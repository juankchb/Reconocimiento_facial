{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNl1vrC9WdXsRlA1RwOol5Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juankchb/Reconocimiento_facial/blob/main/Codigos/capturar_Rostro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import imutils\n",
        "import glob\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "SqSiftIgpSji"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/juankchb/Reconocimiento_facial.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CHFh3qjpWvQ",
        "outputId": "915dcb98-8f63-4b24-f321-a959a6bdde69"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Reconocimiento_facial'...\n",
            "remote: Enumerating objects: 88, done.\u001b[K\n",
            "remote: Counting objects: 100% (88/88), done.\u001b[K\n",
            "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
            "remote: Total 88 (delta 8), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (88/88), 2.83 MiB | 6.42 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Directorio de datos\n",
        "dataPath = '/content/Reconocimiento_facial/Imagenes'\n",
        "\n",
        "# Obtiene la lista de nombres de persona a partir de las carpetas en dataPath\n",
        "personNames = [name for name in os.listdir(dataPath) if os.path.isdir(os.path.join(dataPath, name))]\n",
        "\n",
        "# Directorio que contiene los videos\n",
        "videos_dir = '/content/Reconocimiento_facial/Videos_deteccion_rostro/'\n",
        "\n",
        "faceClassif = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "# Bucle for para procesar cada persona\n",
        "for personName in personNames:\n",
        "    # Ruta completa a la carpeta de la persona\n",
        "    personPath = os.path.join(dataPath, personName)\n",
        "\n",
        "    # Comprueba si la carpeta de la persona existe, si no, la crea\n",
        "    if not os.path.exists(personPath):\n",
        "        print('Carpeta creada:', personPath)\n",
        "        os.makedirs(personPath)\n",
        "\n",
        "    # Nombre del video correspondiente a la persona\n",
        "    video_name = f'{personName}.mp4'\n",
        "    video_path = os.path.join(videos_dir, video_name)\n",
        "\n",
        "    # Verifica si el video existe antes de procesarlo\n",
        "    if os.path.exists(video_path):\n",
        "        # Abre el archivo de video\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "        # Inicializa el contador para las imágenes capturadas\n",
        "        count = 0\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            frame = imutils.resize(frame, width=640)\n",
        "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            auxFrame = frame.copy()\n",
        "            faces = faceClassif.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "            for (x, y, w, h) in faces:\n",
        "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "                rostro = auxFrame[y:y + h, x:x + w]\n",
        "                # Redimensiona la imagen del rostro a 150x150 píxeles\n",
        "                rostro = cv2.resize(rostro, (150, 150), interpolation=cv2.INTER_CUBIC)\n",
        "                # Guarda la imagen en escala de grises\n",
        "                cv2.imwrite(os.path.join(personPath, f'{personName}_rostro_{count}.jpg'), rostro, [cv2.IMWRITE_JPEG_QUALITY, 100])\n",
        "                count += 1\n",
        "\n",
        "            k = cv2.waitKey(1)\n",
        "            if k == 27 or count >= 301:\n",
        "                break\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "84V2rgvTDz7B"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Entrenar_Red_N"
      ],
      "metadata": {
        "id": "rfJv9UT5lCtj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directorio de datos\n",
        "dataPath = '/content/Reconocimiento_facial/Imagenes'\n",
        "\n",
        "# Obtiene la lista de nombres de persona a partir de las carpetas en dataPath\n",
        "personNames = [name for name in os.listdir(dataPath) if os.path.isdir(os.path.join(dataPath, name))]\n",
        "\n",
        "# Directorio que contiene los videos\n",
        "videos_dir = '/content/Reconocimiento_facial/Videos_deteccion_rostro/'\n",
        "\n",
        "# Utiliza glob para obtener la lista de archivos de video en el directorio\n",
        "video_files = glob.glob(os.path.join(videos_dir, '*.mp4'))\n",
        "\n",
        "faceClassif = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "# Listas para almacenar las imágenes de rostros y las etiquetas (nombres)\n",
        "facesData = []\n",
        "labels = []\n",
        "\n",
        "# Bucle for para procesar cada persona\n",
        "for personName in personNames:\n",
        "    # Ruta completa a la carpeta de la persona\n",
        "    personPath = os.path.join(dataPath, personName)\n",
        "\n",
        "    # Nombre del video correspondiente a la persona\n",
        "    video_name = f'{personName}.mp4'\n",
        "    video_path = os.path.join(videos_dir, video_name)\n",
        "\n",
        "    # Verifica si el video existe antes de procesarlo\n",
        "    if os.path.exists(video_path):\n",
        "        # Abre el archivo de video\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            frame = imutils.resize(frame, width=640)\n",
        "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convierte a escala de grises\n",
        "            auxFrame = frame.copy()\n",
        "            faces = faceClassif.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "            for (x, y, w, h) in faces:\n",
        "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "                rostro = auxFrame[y:y + h, x:x + w]\n",
        "                # Redimensiona la imagen del rostro a 150x150 píxeles\n",
        "                rostro = cv2.resize(rostro, (150, 150), interpolation=cv2.INTER_CUBIC)\n",
        "                # Convierte la imagen a escala de grises\n",
        "                rostro = cv2.cvtColor(rostro, cv2.COLOR_BGR2GRAY)\n",
        "                # Agrega la imagen redimensionada a la lista\n",
        "                facesData.append(rostro)\n",
        "                # Usa el nombre de la persona como etiqueta\n",
        "                labels.append(personName)\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "# Convertir los nombres de persona a números únicos\n",
        "label_ids = {name: idx for idx, name in enumerate(set(labels))}\n",
        "labels = [label_ids[name] for name in labels]\n",
        "labels = np.array(labels, dtype=np.int32)\n",
        "\n",
        "# Entrenar el reconocedor de rostros\n",
        "face_recognizer = cv2.face_LBPHFaceRecognizer.create()\n",
        "print(\"Entrenando el reconocedor de rostros...\")\n",
        "face_recognizer.train(facesData, labels)\n",
        "\n",
        "# Almacenar el modelo entrenado\n",
        "model_path = '/content/modeloLBPHFace.xml'\n",
        "face_recognizer.save(model_path)\n",
        "print(f\"Modelo almacenado en {model_path}\")"
      ],
      "metadata": {
        "id": "lX6o6FVzHKK2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d93135e2-f675-4053-8bae-0e6c3208c7fe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando el reconocedor de rostros...\n",
            "Modelo almacenado en /content/modeloLBPHFace.xml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reconocimiento Facial"
      ],
      "metadata": {
        "id": "fVXIrN1Gt8CW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rQcX-Cayq81t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}